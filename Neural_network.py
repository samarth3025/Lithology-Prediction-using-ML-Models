# -*- coding: utf-8 -*-
"""NN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v6LeeJwQp8m4j-dPfLjaN_K7bZ2J_Gyd
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import matplotlib.colors as colors
from mpl_toolkits.axes_grid1 import make_axes_locatable


plt.rcParams['font.size'] = 14
plt.rcParams['figure.figsize'] = (20, 16)
plt.rcParams['figure.facecolor'] = '#00000000'


from pandas import set_option
set_option("display.max_rows", 10)

filename = 'facies_dataset.csv'
training_data = pd.read_csv(filename)
training_data

# log data Preprocessing

facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00',
       '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']

facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS',
                 'WS', 'D','PS', 'BS']
#facies_color_map is a dictionary that maps facies labels
#to their respective colors
facies_color_map = {}
for ind, label in enumerate(facies_labels):
    facies_color_map[label] = facies_colors[ind]
#this enumerate function is used to convert any list to a dictionary with index as its subject.

def label_facies(row, labels):
    return labels[ row['Facies'] -1]

training_data.loc[:,'FaciesLabels'] = training_data.apply(lambda row: label_facies(row, facies_labels), axis=1)

def make_facies_log_plot(logs, facies_colors):
    #make sure logs are sorted by depth
    logs = logs.sort_values(by='Depth')
    cmap_facies = colors.ListedColormap(
            facies_colors[0:len(facies_colors)], 'indexed')

    ztop=logs.Depth.min(); zbot=logs.Depth.max()

    cluster=np.repeat(np.expand_dims(logs['Facies'].values,1), 100, 1)

    f, ax = plt.subplots(nrows=1, ncols=6, figsize=(8, 12))
    ax[0].plot(logs.GR, logs.Depth, '-g')
    ax[1].plot(logs.ILD_log10, logs.Depth, '-')
    ax[2].plot(logs.DeltaPHI, logs.Depth, '-', color='0.5')
    ax[3].plot(logs.PHIND, logs.Depth, '-', color='r')
    ax[4].plot(logs.PE, logs.Depth, '-', color='black')
    im=ax[5].imshow(cluster, interpolation='none', aspect='auto',
                    cmap=cmap_facies,vmin=1,vmax=9)

    divider = make_axes_locatable(ax[5])
    cax = divider.append_axes("right", size="20%", pad=0.05)
    cbar=plt.colorbar(im, cax=cax)
    cbar.set_label((17*' ').join([' SS ', 'CSiS', 'FSiS',
                                'SiSh', ' MS ', ' WS ', ' D  ',
                                ' PS ', ' BS ']))
    cbar.set_ticks(range(0,1)); cbar.set_ticklabels('')

    for i in range(len(ax)-1):
        ax[i].set_ylim(ztop,zbot)
        ax[i].invert_yaxis()
        ax[i].grid()
        ax[i].locator_params(axis='x', nbins=3)

    ax[0].set_xlabel("GR")
    ax[0].set_xlim(logs.GR.min(),logs.GR.max())
    ax[1].set_xlabel("ILD_log10")
    ax[1].set_xlim(logs.ILD_log10.min(),logs.ILD_log10.max())
    ax[2].set_xlabel("DeltaPHI")
    ax[2].set_xlim(logs.DeltaPHI.min(),logs.DeltaPHI.max())
    ax[3].set_xlabel("PHIND")
    ax[3].set_xlim(logs.PHIND.min(),logs.PHIND.max())
    ax[4].set_xlabel("PE")
    ax[4].set_xlim(logs.PE.min(),logs.PE.max())
    ax[5].set_xlabel('Facies')

    ax[1].set_yticklabels([]); ax[2].set_yticklabels([]); ax[3].set_yticklabels([])
    ax[4].set_yticklabels([]); ax[5].set_yticklabels([])
    ax[5].set_xticklabels([])
    f.suptitle('Well: %s'%logs.iloc[0]['Well Name'], fontsize=14,y=0.94)

facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D','PS', 'BS']

facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00',
       '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']

#facies_color_map is a dictionary that maps facies labels to their respective colors

facies_color_map = {}
for ind, label in enumerate(facies_labels):
    facies_color_map[label] = facies_colors[ind]

def label_facies(row, labels):
    return labels[ row['Facies'] -1]

# train_df.loc[:,'FaciesLabels'] = train_df.apply(lambda row: label_facies(row, facies_labels), axis=1)
target = 'Facies'
# target classes
facies_counts = training_data[target].value_counts().sort_index()
facies_counts.index = facies_labels

# Data Preparation
# y value
correct_facies_labels = training_data['Facies'].values

# X value
feature_vectors = training_data.drop(['Formation', 'Well Name', 'Depth','Facies','FaciesLabels'], axis=1)

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Example synthetic data
np.random.seed(42)
X= feature_vectors
# standardize data
sc = StandardScaler()

X = sc.fit_transform(X)
# y = correct_facies_labels

target = 'Facies'

dummies = pd.get_dummies(training_data[target])
facies_classes = dummies.columns
y = dummies.values



# # Split data into training and testing sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Standardize features
# scaler = StandardScaler()
# X_train = scaler.fit_transform(X_train)
# X_test = scaler.transform(X_test)

# # Define the neural network model
# model = Sequential()

# # Input layer and first hidden layer
# model.add(Dense(64, input_dim=7, activation='relu'))  # 64 neurons, ReLU activation

# # Additional hidden layers
# model.add(Dense(512, activation='relu'))
# model.add(Dense(256, activation='relu'))
# model.add(Dense(128, activation='relu'))
# model.add(Dense(64, activation='relu'))
# model.add(Dense(32, activation='relu'))  # 32 neurons, ReLU activation
# # model.add(Dense(16, activation='relu'))  # 16 neurons, ReLU activation

# # Output layer
# model.add(Dense(9, activation='softmax'))  # 9 neurons (one for each class), softmax activation for classification

# # Compile the model
# model.compile(optimizer='adam',
#               loss='categorical_crossentropy',
#               metrics=['accuracy'])

# # Train the model
# history = model.fit(X_train, y_train,
#                     epochs=200,
#                     batch_size=16,
#                     validation_split=0.2,
#                     verbose=2)

# # Evaluate the model
# loss, accuracy = model.evaluate(X_test, y_test, verbose=2)
# print(f"Test loss: {loss}")
# print(f"Test accuracy: {accuracy}")

# # Predictions
# y_pred = model.predict(X_test)

!pip install scikit-optimize

import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import *
from tensorflow.keras.callbacks import *

import skopt
from skopt import gp_minimize, forest_minimize
from skopt.space import Real, Categorical, Integer
from skopt.plots import *
from skopt.utils import use_named_args

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# dim_learning_rate = Real(low=1e-4, high=1e-1, prior='uniform', name='learning_rate')
# dim_num_dense_layers = Integer(low=3, high=10, name='num_dense_layers')
# dim_num_dense_nodes = Integer(low=128, high=512, name='num_dense_nodes')
# dim_activation = Categorical(categories=['relu', 'elu'], name='activation')
# dim_dropout = Integer(low=1, high=5, name='dp')

# dimensions = [
#     dim_learning_rate,
#     dim_num_dense_layers,
#     dim_num_dense_nodes,
#     dim_activation,
#     dim_dropout
# ]


# # set default params - make sure are within the search space
# default_params = [1e-2, 4, 128, 'relu', 1]

pip install tensorflow scikit-learn

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, InputLayer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import precision_score, recall_score, f1_score
from skopt import gp_minimize
from skopt.space import Real, Integer, Categorical
from skopt.utils import use_named_args

# Define the model creation function
def create_model(learning_rate, num_dense_layers, num_dense_nodes, activation, dropout):
    model = Sequential()
    model.add(InputLayer(input_shape=(X.shape[1],)))

    for _ in range(num_dense_layers):
        model.add(Dense(num_dense_nodes, activation=activation))
        model.add(Dropout(0.1*dropout))

    model.add(Dense(y.shape[1], activation='softmax'))

    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    return model

default_params = [1e-2, 4, 128, 'relu', 0.5]

# Define the search space
space = [
    Real(1e-4, 1e-1, name='learning_rate'),
    Integer(3, 10, name='num_dense_layers'),
    Integer(128, 256, name='num_dense_nodes'),
    Categorical(['relu', 'elu'], name='activation'),
    Integer(1, 5, name='dropout')
]

@use_named_args(space)
def fitness(learning_rate, num_dense_layers, num_dense_nodes, activation, dropout):
    model = create_model(learning_rate, num_dense_layers, num_dense_nodes, activation, dropout)

    # dropout = max(0, min(0.5, dropout))
    # Train the model
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128, verbose=0)

    # Evaluate the model
    y_pred_proba = model.predict(X_test)
    y_pred = np.argmax(y_pred_proba, axis=1)
    y_true = np.argmax(y_test, axis=1)

    # Compute metrics
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')

    # Get best accuracy
    best_accuracy = max(history.history['accuracy'])

    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")

    return -best_accuracy  # Minimize the negative accuracy to maximize accuracy

fitness(default_params)

from skopt import gp_minimize

# Perform Bayesian optimization
result = gp_minimize(func=fitness,
                     dimensions=space,
                     n_calls=30,
                     random_state=42,
                     n_jobs=-1)

# Extract the best parameters and score
best_params = result.x
best_accuracy = -result.fun

print(f"Best Accuracy: {best_accuracy:.4f}")
print(f"Best Hyperparameters: {best_params}")

# help(gp_minimize)



